{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f361fb-3ef8-48bc-86d6-09bc32d81a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"lucasmccabe/logiqa\")\n",
    "\n",
    "# 使用select_columns方法保留指定的列\n",
    "processed_dataset = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b98137-a889-4c4d-9c1b-a408b7e658a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"seed.txt\", \"r\") as f:\n",
    "    seed = int(f.read())\n",
    "\n",
    "# 使用保存的种子打乱数据集\n",
    "shuffled_ds = processed_dataset.shuffle(seed=seed)\n",
    "\n",
    "# 选择打乱后的前100条数据\n",
    "random_sample = shuffled_ds.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c95b70-97a7-40f0-82c7-76eb5f11a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to save results to a file\n",
    "def save_results_to_file(results, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "def extract_answer(answer):\n",
    "    match = re.findall(r'\\\\boxed\\{(.*?)\\}', answer)  # Find all occurrences of '()'\n",
    "    if match:\n",
    "        return match[-1]  # Return the last occurrence\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d90f7896-03b0-44f9-88ca-697649975f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_message(other_plans, idx):\n",
    "    prefix_string = \"Here are some proposals from other agents: \"\n",
    "\n",
    "    if len(other_plans) == 0:\n",
    "        return {\"role\": \"user\", \"content\": \"Closely examine your task plan and provide an updated proposal.\"}\n",
    "\n",
    "    for i, plan in enumerate(other_plans):\n",
    "        agent_response = plan[idx][\"content\"]\n",
    "        response = f\"\\n\\n Agent response: ```{agent_response}```\"\n",
    "\n",
    "        prefix_string = prefix_string + response\n",
    "\n",
    "    prefix_string = prefix_string + \"\\n\\n Using these proposals as additional advice, what is your updated task plan?\"\n",
    "\n",
    "    return {\"role\": \"user\", \"content\": prefix_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef480c9f-e6f2-4293-bb26-4bfaf3879b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_of_task(task,options, agents, plan_rounds):\n",
    "    agent_contexts = [[{\"role\": \"user\", \"content\": f\"\"\"\n",
    "    You are an AI agent tasked with constructing a detailed chain of tasks to solve the problem: {task}:{options} . The task chain should consist of interconnected subtasks, where the result of one subtask determines the next steps. For example, if a subtask yields Result A, you should execute Task B; if it yields Result C, you should execute Task D, and so on.\n",
    "\n",
    "Important: Do not provide answers or solutions to the tasks. Your role is solely to create the task chain without solving the tasks themselves.\n",
    "  \"\"\"}] for agent in range(agents)]\n",
    "    \n",
    "    for round in range(plan_rounds):\n",
    "        for i, agent_context in enumerate(agent_contexts):\n",
    "            if round != 0:\n",
    "                other_plans = agent_contexts[:i] + agent_contexts[i+1:]\n",
    "                message = construct_message(other_plans, 2*round - 1)\n",
    "                agent_context.append(message)\n",
    "            try:\n",
    "                completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=agent_context\n",
    "                )\n",
    "            except:\n",
    "                completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=agent_context\n",
    "                )\n",
    "            assistant_message = construct_assistant_message(completion)\n",
    "            agent_context.append(assistant_message)\n",
    "    return agent_contexts\n",
    "def construct_assistant_message(completion):\n",
    "    content = completion.choices[0].message.content\n",
    "    return {\"role\": \"assistant\", \"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d52a5962-a278-4861-b6d2-84ad0a861342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_plan(task,options, agent_contexts):\n",
    "    choices = ''\n",
    "    for i, choice in enumerate(agent_contexts):\n",
    "        choices += f\"{i + 1}. {choice[-1]['content']}\\n\"\n",
    "\n",
    "    prompt = f'''\n",
    "    What is the best task plan for solving this peoblem: {task}:{options}.\\n\n",
    "    Please choose a task plan from these three answers: {choices}\n",
    "    Your answer should be based on the content of one of the task plans, not your reasoning process. \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    except:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52da6ed3-37e4-495b-97f7-1204e41928e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_message_answer(other_answers, idx, task_chain, ids):\n",
    "    prefix_string = f\"\"\"The following is the task plan for your reference : {task_chain}.\"\"\"\n",
    "    prefix_string = prefix_string + \"\\n Here are answers from other agents: \"\n",
    "    if len(other_answers) == 0:\n",
    "        return {\"role\": \"user\", \"content\": \"Closely examine your answer and provide an updated version.\"}\n",
    "\n",
    "    for i, plan in enumerate(other_answers):\n",
    "        agent_answer = plan[idx][\"content\"]\n",
    "        response = f\"\\n\\n Agent {ids[i]} answer: ```{agent_answer}```\"\n",
    "        prefix_string = prefix_string + response\n",
    "\n",
    "    prefix_string = prefix_string + \"\\n\\n Using the solutions from other agents as additional information, and double-checking each subtask of your last answer, can you provide your answer to the math problem? Your final answer should be a single alphabetical index in the form \\\\boxed{{answer}}, at the end of your response.\"\n",
    "    \n",
    "    return {\"role\": \"user\", \"content\": prefix_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a124f5a-4468-40cc-8f0e-745282d53262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(task, agents,task_chain, answer_rounds, options):\n",
    "    agent_contexts = [[{\"role\": \"user\", \"content\": f\"\"\"\n",
    "    Can you solve the following problem? {task}:{options} \n",
    "    Your final answer should be a single alphabetical index in the form \\\\boxed{{answer}}, at the end of your response.\n",
    "    \"\"\"}] for agent in range(agents)]\n",
    "\n",
    "    agent_list = list(range(1, agents + 1))\n",
    "    for round in range(answer_rounds):\n",
    "        for i, agent_context in enumerate(agent_contexts):\n",
    "            if round != 0:\n",
    "                agent_rest = [x for x in agent_list if x != i+1]\n",
    "                other_answers = agent_contexts[:i] + agent_contexts[i+1:]\n",
    "                message = construct_message_answer(other_answers, 2*round - 1, task_chain, agent_rest)\n",
    "                agent_context.append(message)\n",
    "            try:\n",
    "                completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=agent_context\n",
    "                )\n",
    "            except:\n",
    "                completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=agent_context\n",
    "                )\n",
    "            assistant_message = construct_assistant_message(completion)\n",
    "            agent_context.append(assistant_message)\n",
    "    return agent_contexts\n",
    "def construct_assistant_message(completion):\n",
    "    content = completion.choices[0].message.content\n",
    "    return {\"role\": \"assistant\", \"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb7ffc27-416b-48a0-9acf-884a89472e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "option_labels = ['A', 'B', 'C', 'D']  ,
    "for sample  in random_sample:\n",
    "    results = {}\n",
    "    task = sample['context']+ ' ' +sample['query']\n",
    "    correct_label = option_labels[sample['correct_option']]\n",
    "    options = {label: answer for label, answer in zip(option_labels, sample['options'])}\n",
    "    agents = 3\n",
    "    plan_rounds = 2\n",
    "    answer_rounds = 3\n",
    "    agent_contexts = chain_of_task(task,options, agents, plan_rounds)\n",
    "    task_chain = select_plan(task,options, agent_contexts)\n",
    "    answers = get_answer(task, agents, task_chain, answer_rounds, options)\n",
    "    results['graph_contexts'] = agent_contexts\n",
    "    results['task_chain'] = task_chain\n",
    "    results['answer_text'] = answers\n"
    "    extracted_data = [\n",
    "        [(i // 2 + 1, extract_answer(sublist[i]['content'])) for i in range(1, len(sublist), 2)]\n",
    "        for sublist in answers\n",
    "    ]\n",
    "    rounds_data = {}\n",
    "    for round_index in range(len(extracted_data[0])): \n",
    "        round_key = f\"round {round_index + 1}\"\n",
    "        rounds_data[round_key] = [item[round_index][1] for item in extracted_data]\n",
    "    results['answer'] = rounds_data\n",
    "    results['correct_answer'] = correct_label\n",
    "    all_results.append(results)\n",
    "output_file = 'graph_task.json'\n",
    "save_results_to_file(all_results, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be93dfc-f52a-4abd-81af-51d3908371e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83655b-45e2-4440-94b6-0cc63f6ee881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
